# Optimator
Play with optimization algorithms.
### Cauchy (Gradient) method  vs Newton's method
<br>About code.
<br>In this code researched Gradient or Cauchy method - first order method vs Newton's method -  second order method
<br>The code illustrates the advantages of the second order method over the first order method.
<br>The classical gradient algorithm has been writed and ploted its convergence.
<br>The Newton's method has been writed.
<br>This is a second-order method using the Hessian matrix - a matrix of estimates of the second derivatives.
<br>The convergence of Newton's method is investigated vs Gradient convergence.
#### Coded by      Alex Titov
#### Last update   13.01.2021
#### E-mail        alexeytitovwork@gmail.com
